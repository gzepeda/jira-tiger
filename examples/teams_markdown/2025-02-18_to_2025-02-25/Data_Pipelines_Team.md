# Team name: Data Pipelines Team

All the issues below are from the same team.

## Points of Contact
- Victor Bronze
- Wendy Copper

## Updated Issues

- **DPGCP-108** - Develop Data Pipeline Monitoring and Logging

  **Description:**
  > Develop comprehensive monitoring and logging for data pipelines to track performance, detect errors, and ensure data quality.

  **Comments History:**
  > 2025-02-10 - Victor Bronze - Defining what should we track
  > 2025-02-24 - Victor Bronze - Added logging to transformation pipeline.

  **Last Comment (2025-02-24):**
  > Victor Bronze - Added logging to transformation pipeline.

  - issue_link: https://example.com/browse/DPGCP-108
  - status: In Progress
  - created: 2025-01-18
  - last_update: 2025-02-25 00:00:00
  - labels: data-platform-refactoring
  - related_docs: https://docs.google.com/document/d/1aBcDeFgHiJkLmNoPqRsTuVwXyZ01aBcDefGhI/edit
  - workstream: Data Infrastructure

- **DPGCP-156** - Document performance metrics for the most important jobs

  **Description:**
  > Define a documentation with the SLOs and thresholds

  **Comments History:**
  > 2025-02-14 - Wendy Copper - Propose a top 10 jobs for performance monitor
  > 2025-02-25 - Victor Bronze - Creating a performance metrics table for data lake transformation

  **Last Comment (2025-02-25):**
  > Victor Bronze - Creating a performance metrics table for data lake transformation

  - issue_link: https://example.com/browse/DPGCP-156
  - status: In Progress
  - created: 2025-01-25
  - last_update: 2025-02-25 00:00:00
  - labels: data-platform-refactoring
  - related_docs: https://docs.google.com/document/d/1aBcDeFgHiJkLmNoPqRsTuVwXyZ01aBcDefGhI/edit
  - workstream: Data Infrastructure

## Not Updated Issues

- **DPGCP-107** - Implement Error Handling and Retry Mechanisms

  **Description:**
  > Implement robust error handling and retry mechanisms in data pipelines to ensure data delivery and prevent data loss.

  - issue_link: https://example.com/browse/DPGCP-107
  - status: To Do
  - created: 2025-01-16
  - last_update: 2025-01-16 00:00:00
  - labels: data-platform-refactoring
  - related_docs: https://docs.google.com/document/d/1aBcDeFgHiJkLmNoPqRsTuVwXyZ01aBcDefGhI/edit
  - workstream: Data Infrastructure
  - child_issues: DPGCP-202

- **DPGCP-126** - Implement Real-time Data Streaming

  **Description:**
  > Set up a real-time data streaming pipeline using Pub/Sub to ingest data from external sources.

  - issue_link: https://example.com/browse/DPGCP-126
  - status: To Do
  - created: 2025-01-05
  - last_update: 2025-01-05 00:00:00
  - labels: data-platform-refactoring
  - related_docs: https://docs.google.com/document/d/1aBcDeFgHiJkLmNoPqRsTuVwXyZ01aBcDefGhI/edit
  - workstream: Data Infrastructure

- **DPGCP-146** - Ingest data from source A

  **Description:**
  > Create and schedule a new job to ingest data from source A.

  - issue_link: https://example.com/browse/DPGCP-146
  - status: To Do
  - created: 2025-01-15
  - last_update: 2025-01-15 00:00:00
  - labels: data-platform-refactoring
  - related_docs: https://docs.google.com/document/d/1aBcDeFgHiJkLmNoPqRsTuVwXyZ01aBcDefGhI/edit
  - workstream: Data Infrastructure

## This ends all the issues from the team Data Pipelines Team

